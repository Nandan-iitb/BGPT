{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\ajayp\\Downloads\\Final_clean_word_split_hindi.xlsx\")\n",
    "\n",
    "#df['splits']= np.zeros(len(df['Unnamed: 0']))\n",
    "df  = df.fillna(' ')\n",
    "#df.to_csv('C:\\Users\\ajayp\\Downloads\\Final_clean_word_split_hindi_1.xlsx')\n",
    "#df.count(df['Unnamed: 2']==None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['splits']=' '\n",
    "for i in range(len(df['Unnamed: 0'])):\n",
    "    df['splits'][i] = df['Unnamed: 2'][i]+'+'+df['Unnamed: 3'][i] +'+'+df['Unnamed: 4'][i]\n",
    "    if df['Unnamed: 2'][i] == ' ':\n",
    "        df['splits'][i] = df['Unnamed: 3'][i]+'+'+df['Unnamed: 4'][i]\n",
    "    if df['Unnamed: 3'][i] == ' ':\n",
    "        df['splits'][i] = df['Unnamed: 2'][i]+'+'+df['Unnamed: 4'][i] \n",
    "    if df['Unnamed: 4'][i] == ' ':\n",
    "        df['splits'][i] = df['Unnamed: 2'][i]+'+'+df['Unnamed: 3'][i]\n",
    "    #else:\n",
    "   #     df['splits'][i] = df['Unnamed: 2'][i]+'+'+df['Unnamed: 3'][i] +'+'+df['Unnamed: 4'][i]  \n",
    "    \n",
    "df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_chars(words):\n",
    "    unique_chars = set()\n",
    "    for word in words:\n",
    "        print(word)\n",
    "        for char in word:\n",
    "\n",
    "            unique_chars.add(char)\n",
    "    return unique_chars\n",
    "#df = df['stem1'].dropna()\n",
    "all_words = df['Unnamed: 1'].tolist()#+df['stem1'].tolist()\n",
    "print(len(all_words))\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "list4 = []\n",
    "for i in df.index:\n",
    "    list1.append(df['splits'][i])\n",
    "#print(list1)\n",
    "print(len(all_words))\n",
    "unique_chars = extract_unique_chars(all_words)\n",
    "unique_chars1= extract_unique_chars(list1)\n",
    "char_vocab=[]\n",
    "for i in unique_chars:\n",
    "    char_vocab.append(i)\n",
    "for i in unique_chars1:\n",
    "    char_vocab.append(i)\n",
    "char_vocab_1 = set(char_vocab)\n",
    "print(f\"Unique devanagari Characters: {unique_chars} {unique_chars1}\")\n",
    "print(len(char_vocab_1))\n",
    "char_vocab_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def char_tensor(word, char_vocab):\n",
    "    tensor = torch.zeros(len(word), len(char_vocab))\n",
    "    default_char=' '\n",
    "    for i, char in enumerate(word):\n",
    "        if char in char_vocab:\n",
    "            for j in range(len(char_vocab)):\n",
    "                if char_vocab[j]==char:\n",
    "                    tensor[i][j] = 1\n",
    "        else:\n",
    "            print(f\"Warning: Character '{char}' not found in vocabulary. Using default index.\")\n",
    "            tensor[i][-1] = 1  # Use the default character\n",
    "    return tensor\n",
    "print(char_tensor('अङ्कफल',char_vocab))\n",
    "#char_tensor('candra',char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['Unnamed: 1']\n",
    "output_texts = df['splits']\n",
    "\n",
    "input_texts_2 = df['Unnamed: 1']\n",
    "output_texts_2 = df['splits']\n",
    "k=0\n",
    "#for i in X_train.index:\n",
    " #   input_texts[k] = char_tensor(X_train[i],char_vocab)\n",
    "  ##  k+=1\n",
    "# Tokenize the input and output texts\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(output_texts)\n",
    "#input_sequences = np.zeros(max_seq_len)\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "output_sequences = tokenizer.texts_to_sequences(output_texts)\n",
    "max_seq_len = 15\n",
    "input_sequences = pad_sequences(input_sequences, max_seq_len, padding ='post')\n",
    "output_sequences = pad_sequences(output_sequences, max_seq_len, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = np.array([to_categorical(x, num_classes=len(char_vocab_1)) for x in input_sequences])\n",
    "Y_one_hot = np.array([to_categorical(y, num_classes=len(char_vocab_1)) for y in output_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10  # Number of unique integers in the input\n",
    "sequence_length = 5  # Length of the input sequences\n",
    "hidden_units = 180  # Number of hidden units in the RNN\n",
    "batch_size = 32  # Batch size for training\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential([\n",
    "#    SimpleRNN(100, input_shape=(15, len(char_vocab_1)), return_sequences=True),\n",
    "#    TimeDistributed(Dense(input_size, activation='softmax'))\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_one_hot, Y_one_hot, epochs=5, batch_size=320)\n",
    "\n",
    "print(f\"X_one_hot shape: {X_one_hot.shape}\")  # Should be (num_samples, sequence_length, input_size)\n",
    "print(f\"Y_one_hot shape: {Y_one_hot.shape}\")  # Should be (num_samples, sequence_length, input_size)\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(hidden_units, input_shape=(max_seq_len, 96), return_sequences=True)),\n",
    "    Dropout(0.3),])\n",
    "    #SimpleRNN(hidden_units, input_shape= hidden_units,return_sequences=True)),\n",
    "    #Dropout(0.4),\n",
    "    #TimeDistributed(Dense(96, activation='softmax'))])\n",
    "#model.add(Bidirectinal(hidden_units))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences = True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(TimeDistributed(Dense(96, activation='softmax')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True)\n",
    "\n",
    "# Train the model with validation split and early stopping\n",
    "history = model.fit(\n",
    "    X_one_hot, Y_one_hot,\n",
    "    epochs=200,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    #callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model val_loss')\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot\n",
    "\n",
    "model.save('Bidirectional_Splitting_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_sequence(model, input_sequence):\n",
    "    input_one_hot = to_categorical(input_sequence, num_classes=96)#.reshape((1, 15, 96))\n",
    "   # input_one_hot = pad_sequences(input_one_hot,maxlen=15,padding='post')\n",
    "    output_one_hot = model.predict(input_one_hot)\n",
    "    output_sequence = np.argmax(output_one_hot, axis=2)\n",
    "    \n",
    "    return output_sequence.flatten()\n",
    "\n",
    "list=[]\n",
    "list2=[]\n",
    "for input_sequence_1 in df['Unnamed: 1'][:10]:\n",
    "    i = tokenizer.texts_to_sequences(input_sequence_1)\n",
    "    i = pad_sequences(i,maxlen=15, padding='post')\n",
    "    output_sequence_1 = generate_output_sequence(model, i)\n",
    "    list2.append([input_sequence_1])\n",
    "    list.append(tokenizer.sequences_to_texts([output_sequence_1]))\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in tokenizer.sequences_to_texts(list):\n",
    "    i=i.replace(' ', '')\n",
    "    i=i.replace('++','+')\n",
    "    i=i.replace('+++','+')\n",
    "    i=i.replace('++++','+')\n",
    "    i=i.replace('++','+')\n",
    "    print(list2[k])\n",
    "    print(i)\n",
    "    k+=1\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted']=np.zeros((len(df['Unnamed: 1']),15))\n",
    "k = model.predict(X_one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_token_level_metrics(true_sequences, predicted_sequences):\n",
    "    \"\"\"\n",
    "    Calculate token-level precision, recall, and F1 score for word splitting.\n",
    "\n",
    "    Parameters:\n",
    "    true_sequences (list of list of str): The ground truth token sequences.\n",
    "    predicted_sequences (list of list of str): The predicted token sequences.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    assert len(true_sequences) == len(predicted_sequences), \"Number of sequences must match.\"\n",
    "\n",
    "    # Flatten the lists\n",
    "    true_tokens = [token for seq in true_sequences for token in seq]\n",
    "    predicted_tokens = [token for seq in predicted_sequences for token in seq]\n",
    "\n",
    "    # Create a binary representation of the presence of each token\n",
    "    unique_tokens = list(set(true_tokens + predicted_tokens))\n",
    "    true_binary = [[1 if token in seq else 0 for token in unique_tokens] for seq in true_sequences]\n",
    "    predicted_binary = [[1 if token in seq else 0 for token in unique_tokens] for seq in predicted_sequences]\n",
    "\n",
    "    # Flatten binary representations\n",
    "    true_binary_flat = [item for sublist in true_binary for item in sublist]\n",
    "    predicted_binary_flat = [item for sublist in predicted_binary for item in sublist]\n",
    "\n",
    "    precision = precision_score(true_binary_flat, predicted_binary_flat, average='macro')\n",
    "    recall = recall_score(true_binary_flat, predicted_binary_flat, average='macro')\n",
    "    f1 = f1_score(true_binary_flat, predicted_binary_flat, average='macro')\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "true_sequences = df['splits']\n",
    "predicted_sequences = df['predicted'] \n",
    "\n",
    "metrics = calculate_token_level_metrics(true_sequences, predicted_sequences)\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
